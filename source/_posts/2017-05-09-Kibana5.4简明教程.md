---
layout: post
title:  "Kibana 5.4简明教程"
subtitle: "Kibana 5.4 官方文档中文版"
date:   2017-05-09 22:01:00 +0800
categories: ELK
header-img: img/posts/kibana5.4/cover.png
tags:
 - elastic
 - kibana
 - 译文
---

> 本文翻译自[Kibana5.4版本官方教程](https://www.elastic.co/guide/en/kibana/5.4/getting-started.html)。文章首发于我的个人博客网站[梧桐和风的博客](http://img.wthfeng.com/),欢迎关注。


## 开始

想要得到一些关于Kibana的实际经验吗，下面教程会叫你怎样做。

- 向Elasticsearch导入一些样本数据
- 定义一个索引模式
- 用[Discover](https://www.elastic.co/guide/en/kibana/current/discover.html)搜索样本数据
- 为样本数据建立[visualizations](https://www.elastic.co/guide/en/kibana/current/visualize.html)【可视化图表组件】
- 将可视化数据汇集到[Dashboard](https://www.elastic.co/guide/en/kibana/current/dashboard.html)

开始之前，你必须确保已[成功安装Kibana](https://www.elastic.co/guide/en/kibana/current/install.html),并且能[连上Elasticsearch](https://www.elastic.co/guide/en/kibana/current/connect-to-elasticsearch.html)


## 加载样本数据

本部分内容依赖下列数据

- 莎士比亚全集,已适当分析成字段。点击下载[shakespeare.json](https://download.elastic.co/demos/kibana/gettingstarted/shakespeare.json)
- 一组随机的账户信息。点击下载[accounts.zip](https://download.elastic.co/demos/kibana/gettingstarted/accounts.zip)
- 一组随机生成的日志文件。点击下载[logs.josnl.gz](https://download.elastic.co/demos/kibana/gettingstarted/logs.jsonl.gz)


下载完成后，用下面的命令解压文件

```shell
unzip accounts.zip
gunzip logs.jsonl.gz

```

莎士比亚全集的数据结构如下：

```json
{
    "line_id": integer,
    "play_name": "String",
    "speech_number": integer,
    "line_number": "String",
    "speaker": "String",
    "text_entry": "String",
}

```
账户信息的数据结构如下：

```json
{
    "account_number":integer,
    "balance":integer,
    "firstname": "String",
    "lastname": "String",
    "age":integer,
    "gender": "M or F",
    "address": "String",
    "employer": "String",
    "email": "String",
    "city": "String",
    "state": "String"
}

```

日志文件的数据信息有十几个字段，在这里我们主要使用如下几个字段：

```json
{
    "memory": integer,
    "geo.coordinates": "geo_point",
    "@timestamp":"date"
}

```

在我们加载莎士比亚数据和日志文档时，需要为这些字段建立映射（Mapping），映射将索引中的文档划分成逻辑组，并指定文档的特性。比如文档的可分析性或是否可被标记、可被分析等特性。

使用下面的终端命令（比如使用`bash`）设置莎士比亚数据的映射。

```bash
curl -H 'Content-Type: application/json' -XPUT http://localhost:9200/shakespeare -d '
{
 "mappings" : {
  "_default_" : {
   "properties" : {
    "speaker" : {"type": "string", "index" : "not_analyzed" },
    "play_name" : {"type": "string", "index" : "not_analyzed" },
    "line_id" : { "type" : "integer" },
    "speech_number" : { "type" : "integer" }
   }
  }
 }
}
';

```
下面一一来分析该映射含义：

- `speaker`字段为不能被分析字符串类型。表明该字段将被当做独立的单元处理，即使包含多个词。
- `play_name`处理同上。
- `line_id`和`speech_number`字段为数值类型。

使用以下命令为日志文件创建`geo_point`类型的映射。

```bash
curl -H 'Content-Type: application/json' -XPUT http://localhost:9200/logstash-2015.05.18 -d '
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}
';

```

```bash
curl -H 'Content-Type: application/json' -XPUT http://localhost:9200/logstash-2015.05.19 -d '
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}
';

```

```bash
curl -H 'Content-Type: application/json' -XPUT http://localhost:9200/logstash-2015.05.20 -d '
{
  "mappings": {
    "log": {
      "properties": {
        "geo": {
          "properties": {
            "coordinates": {
              "type": "geo_point"
            }
          }
        }
      }
    }
  }
}
';
```

有关账户信息的数据不需要建立映射。现在我们来把这些数据导入到Elasticsearch中。这里需要用到[Elasticsearch bulk API](https://www.elastic.co/guide/en/elasticsearch/reference/5.4/docs-bulk.html)


```bash
curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/bank/account/_bulk?pretty' --data-binary @accounts.json

curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/shakespeare/_bulk?pretty' --data-binary @shakespeare.json

curl -H 'Content-Type: application/x-ndjson' -XPOST 'localhost:9200/_bulk?pretty' --data-binary @logs.jsonl

```

执行以下命令可能需要一些时间，至于多少就要看你的计算机性能水平了。可用下面命令验证是否导入成功：

> curl 'localhost:9200/_cat/indices?v'

若执行成功，你应该能看到类似下面的输出

```bash
health status index               pri rep docs.count docs.deleted store.size pri.store.size
yellow open   bank                  5   1       1000            0    418.2kb        418.2kb
yellow open   shakespeare           5   1     111396            0     17.6mb         17.6mb
yellow open   logstash-2015.05.18   5   1       4631            0     15.6mb         15.6mb
yellow open   logstash-2015.05.19   5   1       4624            0     15.7mb         15.7mb
yellow open   logstash-2015.05.20   5   1       4750            0     16.4mb         16.4mb

```

## 定义你的索引模式

每个加载到Elasticsearch的数据集需要一个索引模式（index pattern）。
在前面的章节里，莎士比亚数据集的索引名为`shakespeare `,账户数据集的索引名为`bank`。**索引模式是一个含有可选通配符的字符串，它能匹配多个索引**。举个例子，在常见的日志中，一个包含日期的索引名如`YYYY.MM.DD`，则对应5月的索引模式应该是`logstach-2915-05*`这样。

在该文档中，任何被匹配的索引都将被Kibana分析并处理。打开浏览器访问`localhost:5601`,【译者注：需保证同时开启Elasticsearch和Kibana】单击左侧面板的`Management`标签，会出现`Configure an index pattern`页面。在`Index name or pattern`填入`shakes*`以便能匹配莎士比亚数据集的数据。这时需注意不要勾选`Index contains time-based events`选项。随后点击`create`即可。照此再创建一个索引模式名为`ba*`,以能匹配账户信息。

日志文件数据集是基于时间的，所以再创建第3个索引模式，这时选中`Index contains time-based events`选项，选择`@timestamp`字段作为分析日期的依据。

## 探索你的数据

点击左侧面板中的`Discover`标签。即进入探索（Discover）数据页面。

![](/img/posts/kibana5.4/tutorial-discover.png)

最上端是查询框，你可以输入[Elasticsearch 查询语句](https://www.elastic.co/guide/en/elasticsearch/reference/5.4/query-dsl-query-string-query.html#query-string-syntax)查询你的数据。你可以导出查询结果，根据保存结果创建可视化图表（visualizations）。

当前匹配的索引数据展示在搜索框下面。索引模式决定了在你搜索时哪些索引的数据会显示出来。

你可以直接用字段名或你感兴趣的任何值来构建你的查询。对应数值字段，你可以直接使用`>`,`<`,`=`等运算符。或者，你可以用 `AND`、`OR`,`NOT`等逻辑运算符连接你的查询元素。

比如，选择`ba*`模式匹配然后在查询框中输入下列查询

> account_number:<100 AND balance:>47500

该查询将返回账户在0至99之间的，余额在47500以上的所有数据。如下图所示，它返回了5条数据，账户分别是`8,32,78,85,97`。

![](/img/posts/kibana5.4/tutorial-discover-2.png)


默认情况下，每条数据将显示所有字段。为了只让需要的字段显示，你可以在左侧展示字段的区域点击要显示字段右侧的`add`按钮。

![](/img/posts/kibana5.4/tutorial-discover-3.png)


## 可视化你的数据

点击左侧面板的`Visualize`按钮开始可视化数据。

![](/img/posts/kibana5.4/tutorial-visualize-landing.png)

可视化工具能够以多种方式观察分析你的数据，下面我们就用饼状图来分析一下账户信息数据集。点击下图的`Create a visualization `开始我们的实践。

下面展示了几种分析数据的可视化类型，点击`pie`类型。

![](/img/posts/kibana5.4/tutorial-visualize-wizard-step-1.png)


你可以用保存的数据完成可视化工作，或者重建一个搜索条件。由于我们要分析账户信息数据，所以选择`ba*`索引模式。

![](/img/posts/kibana5.4/tutorial-visualize-wizard-step-2.png)


默认搜索匹配所有文档数据，现在，饼状图是单个的“一大块”

![](/img/posts/kibana5.4/tutorial-visualize-pie-1.png)


为了指定要在图表中显示哪些分片，我们需要使用Elasticsearch的[buncket聚合](https://www.elastic.co/guide/en/elasticsearch/reference/5.4/search-aggregations.html)（即桶聚合）。桶聚合会将符合搜索条件的文档分为不同的类别。例如，帐户数据包括每个帐户的余额，使用桶聚合，可以建立多个帐户余额范围，并找出每个范围的账户数量。

下面是建立桶聚合的过程：

1. 点击`Split Slices`桶类型
2. 在`Aggregation`下拉列表中选择`Range`聚合类型
3. 在`Field`列表中选择`balance`字段
4. 点击`Add Range`依次输入下列范围
5. 点击`Apply changes`执行分析。

```
0             999
1000         2999
3000         6999
7000        14999
15000       30999
31000       50000

```
现在你能看到每个范围内的具体分布。

![](/img/posts/kibana5.4/tutorial-visualize-pie-2.png)

让我们看看数据的另一个维度：帐户持有者的年龄。通过添加另一个桶聚合，您可以在每个余额范围内查看帐户持有人的年龄

1. 点击`Add sub-buckets`按钮添加一个子聚合。
2. 点击`Split Slices`聚合类型
3. 从聚合列表中选择`Terms`
4. 在字段列表选择`age`字段
5. 点击`Apply changes`执行分析。

现在你可以看到帐户持有人的年龄在上述各个范围的分布状况

![](/img/posts/kibana5.4/tutorial-visualize-pie-3.png)

若要保存此图表，以便以后使用它，单击“save”并输入"Pie Example"。

接下来，让我们来看看莎士比亚数据集的怎样在条形图中显示和分析。

1. 在“选择可视化类型”页面点击`Vertical Bar`类型。
2. 选择`shakes*`索引模式。
3. 为在Y轴显示每部戏中演讲者的数量，需要配置Y轴方向的度量值。选择`Unique Count`度量类型以及`speaker`字段。另外，你可以为该统计自定义一个标签名，比如这里称为` Speaking Parts`。
4. 创建`X-Axis`聚合类型。选择`Terms`类型及`play_name`字段，可在自定义标签中写`Play Name`。
5. 点击`Apply changes`执行分析。

![](/img/posts/kibana5.4/tutorial-visualize-bar-2.png)

注意剧本名是如何表现出来的，而不是被分解成单个的单词。这是因为我们在开始就设置了`play_name`是不被分析的。

下面再来一点复杂的，你可能好奇每部戏中最大的对白台词是多少，你可以这样做：

1. 点击`metrics`再添加一个Y轴聚合
2. 选择`Max`聚合类型及`speech_number`字段
3. 选择`Options`选项卡，将`Bar Mode` 改为 `grouped`模式。【译者注：这里在我这的版本并没有看到该选项，不知是不是版本问题，若同此，选择`Metrics&Axes`,在相应聚合下将`Mode`的`stack`改为`mormal`】
4. 点击`Apply changes`执行分析。

![](/img/posts/kibana5.4/tutorial-visualize-bar-3.png)

保存图表并将其命名为 `Bar Example`.

接下来，我们将使用瓦片地图（Tile Map）来可视化我们日志文件示例数据中的地理信息。

1. 在“选择可视化类型”页面点击`Tile map`类型。
2. 选择`logstash-*`索引模式
3. 点击右上角时间按钮，在弹出的时间选择面板中选择`absolute`,然后将时间定为起始2015-05-18到2015-05-20区间。
   ![](/img/posts/kibana5.4/tutorial-timepicker.png)
4. 选择`Geohash`聚合类型,点击`Apply changes`执行分析即可看到如下信息

    ![](/img/posts/kibana5.4/tutorial-visualize-map-2.png)


你可以通过地图左上角的按钮对地图进行放大缩小、看清地图所有点及各种操作。

 ![](/img/posts/kibana5.4/tutorial-visualize-map-3.png)

最后可以点击`save`保存该结果，并命名为`Map Example`。


最后，可以使用`Markdown widget`来制作markdown编辑器。

1. 在“选择可视化类型”页面点击`Other`中的`MarkDown`类型。
2. 接下来就可以编写markdown文档了。

![](/img/posts/kibana5.4/tutorial-visualize-md-2.png)

## 用Dashboards集中展示数据

Dashboards(仪表盘)可将上部分的可视化图表组件集中起来。你可以通过以下步骤完成。

1. 点击左侧面板的`Dashboard`标签。
2. 点击`Add`,可显示出你在`visualizations`保存的可视化图列表
3. 选取要显示在仪表盘的可视化组件，这里我们选择`Markdown Example`, `Pie Example`, `Bar Example`, and `Map Example`。

好了，仪表盘就这样做好了

![](/img/posts/kibana5.4/tutorial-dashboard.png)















































